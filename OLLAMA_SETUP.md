# Ollama Setup Guide f칬r Remissorterare

## 游 Vad 칛r Ollama?

Ollama 칛r en lokal AI-server som l친ter dig k칬ra stora spr친kmodeller (LLMs) direkt p친 din maskin. Det 칛r perfekt f칬r Remissorterare eftersom det ger AI-funktionalitet utan att skicka data externt.

## 游닍 Installation

### macOS
```bash
# Ladda ner och installera
curl -fsSL https://ollama.ai/install.sh | sh

# Starta Ollama
ollama serve
```

### Linux
```bash
# Ladda ner och installera
curl -fsSL https://ollama.ai/install.sh | sh

# Starta Ollama
ollama serve
```

### Windows
```bash
# Ladda ner fr친n: https://ollama.ai/download
# K칬r installeraren och f칬lj instruktionerna
```

## 游뱄 Ladda ner modeller

### Llama 2 (rekommenderad)
```bash
# Ladda ner Llama 2 7B (snabb och effektiv)
ollama pull llama2:7b

# Eller ladda ner Llama 2 13B (b칛ttre kvalitet, l친ngsammare)
ollama pull llama2:13b
```

### Andra modeller
```bash
# Mistral (bra svenska)
ollama pull mistral:7b

# Code Llama (bra f칬r tekniska texter)
ollama pull codellama:7b

# Llama 2 Uncensored (mer flexibel)
ollama pull llama2-uncensored:7b
```

## 丘뙖잺 Konfiguration

### 1. Starta Ollama-server
```bash
# I en terminal
ollama serve
```

### 2. Testa anslutning
```bash
# I en annan terminal
curl 

```

### 3. Konfigurera Remissorterare
Redigera `ai_config.py`:
```python
LOKAL_AI_MODEL = "ollama"  # Anv칛nd Ollama som standard
```

## 游댢 Fels칬kning

### Ollama startar inte
```bash
# Kontrollera att Ollama 칛r installerat
which ollama

# Starta om Ollama
pkill ollama
ollama serve
```

### Modell laddas inte
```bash
# Kontrollera tillg칛ngliga modeller
ollama list

# Ladda ner modell igen
ollama pull llama2:7b
```

### Anslutningsfel
```bash
# Kontrollera att Ollama k칬rs
curl http://localhost:11434/api/tags

# Om det inte fungerar, starta om Ollama
ollama serve
```

## 游늵 Prestanda

### Modellstorlekar
- **7B modeller**: ~4GB RAM, snabba
- **13B modeller**: ~8GB RAM, b칛ttre kvalitet
- **30B+ modeller**: ~16GB+ RAM, h칬gsta kvalitet

### Rekommendationer
- **4-8GB RAM**: Anv칛nd 7B modeller
- **8-16GB RAM**: Anv칛nd 13B modeller
- **16GB+ RAM**: Kan anv칛nda 30B+ modeller

## 游꿢 Anv칛ndning i Remissorterare

1. **Starta Ollama**: `ollama serve`
2. **V칛lj modell** i webbgr칛nssnittet: "Ollama (Llama 2)"
3. **Testa AI-f칬rslag** p친 remisser
4. **F친 intelligenta f칬rslag** p친 nya verksamheter

## 游 S칛kerhet

- **All data k칬rs lokalt** - inget skickas externt
- **Ingen internetanslutning** kr칛vs efter nedladdning
- **Fullst칛ndig kontroll** 칬ver dina data
- **GDPR-kompatibel** f칬r k칛nslig medicinsk information

## 游닄 Mer information

- [Ollama Documentation](https://ollama.ai/docs)
- [Modellbibliotek](https://ollama.ai/library)
- [Community](https://github.com/ollama/ollama/discussions)
