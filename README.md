# Remissorterare

Ett avancerat Python-program f√∂r automatisk hantering av inscannade remisser (PDF:er) med AI-driven verksamhetsidentifiering och f√∂rberedelse av data f√∂r import i andra system.

## üöÄ Funktioner

- **OCR-bearbetning**: Konverterar bildbaserade PDF:er till text med hj√§lp av Tesseract OCR
- **AI-driven analys**: Intelligent verksamhetsidentifiering med OpenAI eller lokala AI-modeller
- **Machine Learning**: F√∂rb√§ttrad verksamhetsidentifiering med TF-IDF och Random Forest
- **Web-baserat gr√§nssnitt**: Modern drag-and-drop interface med realtidsstatus och statistik
- **Automatisk sortering**: Identifierar verksamhet med h√∂g precision och kontextbaserad analys
- **Datautl√§sning**: Extraherar personnummer och remissdatum
- **Intelligent beslutslogik**: Sorterar remisser baserat p√• sannolikhetspo√§ng och AI-analys
- **Strukturerad output**: Skapar .dat-filer f√∂r import i S√§lma
- **Realtidsuppdateringar**: WebSocket-baserad kommunikation
- **Statistik och rapportering**: Visar bearbetningsstatistik i realtid
- **Omdirigering av os√§kra remisser**: M√∂jlighet att manuellt omf√∂rdela och tr√§na modellen
- **Debug-verktyg**: Steg-f√∂r-steg analys av verksamhetsidentifiering
- **Lokal AI-st√∂d**: K√∂r AI-modeller direkt p√• din maskin utan internetanslutning

## üõ†Ô∏è Installation

### Snabbinstallation (rekommenderat)

```bash
# Klona eller ladda ner projektet
cd remissorterare

# G√∂r installationsskriptet k√∂rbart
chmod +x install.sh

# K√∂r installationsskriptet
./install.sh
```

**Vad installationsskriptet g√∂r automatiskt:**
- ‚úÖ Installerar Python 3.12 via pyenv
- ‚úÖ Installerar Tesseract OCR med svenska spr√•kst√∂d
- ‚úÖ Installerar Poppler f√∂r PDF-konvertering (macOS/Linux)
- ‚úÖ Skapar virtuell Python-milj√∂
- ‚úÖ Installerar alla Python-beroenden
- ‚úÖ Installerar lokala AI-bibliotek
- ‚úÖ Valfritt OpenAI-st√∂d
- ‚úÖ Skapar mappstruktur och verksamhetsmappar
- ‚úÖ Konfigurerar AI-inst√§llningar
- ‚úÖ Testar installationen
- ‚úÖ Skapar startskript
- ‚úÖ Kontrollerar virtuell milj√∂ vid k√∂rning

### Manuell installation

#### F√∂ruts√§ttningar

1. **Python 3.8 eller senare**
2. **Tesseract OCR** (kr√§vs f√∂r textigenk√§nning)

#### Installera Tesseract

**macOS:**
```bash
brew install tesseract
brew install tesseract-lang  # F√∂r svenska spr√•kst√∂d
```

**Ubuntu/Debian:**
```bash
sudo apt update
sudo apt install tesseract-ocr
sudo apt install tesseract-ocr-swe  # Svenska spr√•kst√∂d
sudo apt install poppler-utils      # PDF-konvertering
```

**macOS:**
```bash
brew install tesseract
brew install tesseract-lang  # F√∂r svenska spr√•kst√∂d
brew install poppler         # PDF-konvertering
```

**Windows:**
Ladda ner fr√•n: https://github.com/UB-Mannheim/tesseract/wiki

#### Installera Ollama (rekommenderat)

**macOS:**
```bash
brew install ollama
```

**Linux:**
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

**Starta Ollama:**
```bash
ollama serve
```

**Installera standardmodell:**
```bash
ollama pull llama2:7b
```

#### Installera Python-beroenden

**Automatisk installation (rekommenderat):**
```bash
# K√∂r det kompletta installationsskriptet
./install.sh
```

**Manuell installation:**
```bash
# Grundl√§ggande beroenden
pip install pytesseract pdf2image Pillow opencv-python numpy python-dateutil scikit-learn joblib Flask Flask-SocketIO Werkzeug

# Lokala AI-modeller (rekommenderat)
pip install transformers torch sentence-transformers

# OpenAI-st√∂d (valfritt)
pip install openai
```

## ü§ñ AI-konfiguration

### Ollama-modeller (rekommenderat)

Programmet st√∂der nu **Ollama** - lokala stora spr√•kmodeller som k√∂rs direkt p√• din maskin:

#### **Tillg√§ngliga modeller:**
- **`llama2:7b`** (4.7GB): Snabb och effektiv, bra f√∂r svenska
- **`mistral:7b-instruct`** (4.1GB): Optimerad f√∂r instruktioner, utm√§rkt f√∂r svenska
- **`llama2:13b`** (8.5GB): H√∂gre kvalitet, kr√§ver mer minne (16GB RAM)
- **`llama2:70b`** (39GB): H√∂gsta kvalitet, kr√§ver mycket minne (32GB RAM)
- **`codellama:7b`** (4.7GB): Bra f√∂r strukturerad text
- **`qwen:7b`** (4.7GB): Modern modell med bra svenska st√∂d
- **`phi:2.7b`** (1.7GB): Liten men effektiv (4GB RAM)

#### **Rekommenderade modeller f√∂r svenska:**
1. **`mistral:7b-instruct`** - B√§sta balansen mellan kvalitet och hastighet
2. **`llama2:7b`** - Bra standardmodell
3. **`llama2:13b`** - Om du har tillr√§ckligt med RAM

#### **Installera Ollama:**
```bash
# macOS
brew install ollama

# Linux
curl -fsSL https://ollama.ai/install.sh | sh

# Starta Ollama
ollama serve
```

#### **Hantera modeller:**
```bash
# Lista tillg√§ngliga modeller
python ollama_manager.py list

# Installera en modell
python ollama_manager.py install llama2:7b

# Testa en modell
python ollama_manager.py test mistral:7b-instruct

# S√§tt standardmodell
python ollama_manager.py set-default mistral:7b-instruct
```

#### **Webbgr√§nssnitt:**
G√• till `/ollama` f√∂r en komplett webbgr√§nssnitt f√∂r modellhantering:
- Installera modeller
- Byt mellan modeller
- Testa modeller
- Se status och prestanda

### Andra lokala AI-modeller

Programmet st√∂der √§ven andra lokala AI-modeller:

- **Sentence Transformer**: Liten, snabb modell (117MB) - bra f√∂r svenska
- **Swedish BERT**: Svensk BERT-modell (438MB) - h√∂g precision
- **Multilingual BERT**: Internationell modell (1.1GB) - st√∂der m√•nga spr√•k

**Konfigurera f√∂r lokala AI:**
```python
# I ai_config.py
AI_TYPE = "lokal"
LOKAL_AI_MODEL = "ollama"  # eller "sentence_transformer", "swedish_bert", "multilingual_bert"
```

### OpenAI-integration (valfritt)

F√∂r att anv√§nda OpenAI:

1. **S√§tt API-nyckel:**
   ```bash
   export OPENAI_API_KEY="sk-1234567890abcdef..."
   ```

2. **Konfigurera:**
   ```python
   # I ai_config.py
   AI_TYPE = "openai"
   OPENAI_MODEL = "gpt-3.5-turbo"
   ```

## üìÅ Anv√§ndning

### Grundl√§ggande anv√§ndning

1. **Mappstrukturen skapas automatiskt** av installationsskriptet:
   ```
   remissorterare/
   ‚îú‚îÄ‚îÄ input/          # L√§gg PDF-filer h√§r
   ‚îú‚îÄ‚îÄ output/         # Sorterade filer hamnar h√§r
   ‚îÇ   ‚îú‚îÄ‚îÄ Ortopedi/
   ‚îÇ   ‚îú‚îÄ‚îÄ Kirurgi/
   ‚îÇ   ‚îú‚îÄ‚îÄ Kardiologi/
   ‚îÇ   ‚îú‚îÄ‚îÄ Gynekologi/
   ‚îÇ   ‚îî‚îÄ‚îÄ osakert/    # Os√§kra remisser
   ‚îú‚îÄ‚îÄ models/         # AI-modeller och cache
   ‚îî‚îÄ‚îÄ remiss_sorterare.py
   ```

2. **K√∂r programmet**:

   **Kommando-rad version**:
   ```bash
   # Anv√§nd det automatiskt skapade startskriptet
   ./start.sh
   
   # Eller starta manuellt
   source venv/bin/activate
   python remiss_sorterare.py
   ```

   **Web-baserat gr√§nssnitt**:
   ```bash
   # Anv√§nd det automatiskt skapade startskriptet
   ./start_web.sh
   
   # Eller starta manuellt
   source venv/bin/activate
   python web_app.py
   ```

### Ollama-modellhantering

#### **Webbgr√§nssnitt:**
1. Starta webbapplikationen: `./start_web.sh`
2. G√• till `/ollama` f√∂r modellhantering
3. Installera, byt och testa olika modeller

#### **Kommandoradsverktyg:**
```bash
# Aktivera virtuell milj√∂
source venv/bin/activate

# Lista tillg√§ngliga modeller
python ollama_manager.py list

# Installera en modell
python ollama_manager.py install mistral:7b-instruct

# Testa en modell
python ollama_manager.py test llama2:7b

# S√§tt standardmodell
python ollama_manager.py set-default mistral:7b-instruct
```

#### **Automatisk modellhantering:**
- Programmet kontrollerar automatiskt vilka modeller som √§r installerade
- Fallback till standardmodell om vald modell saknas
- Automatisk validering av modellkompatibilitet

### Schemalagd k√∂rning

#### macOS/Linux (cron):
```bash
# √ñppna crontab
crontab -e

# L√§gg till f√∂r k√∂rning varje timme
0 * * * * cd /s√∂kv√§g/till/remissorterare && ./venv/bin/python run_scheduled.py

# Eller anv√§nd startskriptet
0 * * * * cd /s√∂kv√§g/till/remissorterare && ./start.sh
```

#### Windows (Task Scheduler):
1. √ñppna Task Scheduler
2. Skapa en ny uppgift
3. Ange s√∂kv√§g till Python och skriptet
4. S√§tt schemat efter behov

## ‚öôÔ∏è Konfiguration

### Huvudkonfiguration

Redigera `config.py` f√∂r att anpassa:

- **Verksamheter och nyckelord**: L√§gg till eller √§ndra verksamheter
- **Tr√∂skelv√§rden**: √Ñndra sannolikhetstr√∂skel (standard: 70% f√∂r AI, 90% f√∂r fallback)
- **OCR-inst√§llningar**: Justera DPI och spr√•k
- **Mappnamn**: Anpassa mappstruktur

### AI-konfiguration

Redigera `ai_config.py` f√∂r AI-inst√§llningar:

#### **Ollama-konfiguration:**
```python
# I ai_config.py
AI_TYPE = "lokal"
LOKAL_AI_MODEL = "ollama"

# I ollama_config.py kan du √§ndra standardmodell
DEFAULT_OLLAMA_MODEL = "mistral:7b-instruct"  # √Ñndra till √∂nskad modell
```

```python
# AI-typ
AI_TYPE = "lokal"  # "lokal" eller "openai"

# Lokala AI-modeller
LOKAL_AI_MODEL = "sentence_transformer"
LOKAL_AI_DOWNLOAD_MODELS = True

# OpenAI (endast om AI_TYPE = "openai")
OPENAI_MODEL = "gpt-3.5-turbo"
OPENAI_TEMPERATURE = 0.1
AI_CONFIDENCE_THRESHOLD = 70
```

## üß† AI och Machine Learning

### AI-driven verksamhetsidentifiering

Programmet anv√§nder nu AI som prim√§r metod f√∂r verksamhetsidentifiering:

1. **AI-analys** (70%+ sannolikhet): Anv√§nder OpenAI eller lokala modeller
2. **ML-fallback**: Machine Learning med TF-IDF och Random Forest
3. **Regelbaserad fallback**: F√∂rb√§ttrad nyckelordsanalys med kontextbaserad po√§ngs√§ttning
4. **Os√§ker klassificering**: Returnerar "osakert" vid l√•g sannolikhet

### Lokala AI-modeller

**F√∂rdelar:**
- ‚úÖ Ingen internetanslutning kr√§vs
- ‚úÖ Inga API-kostnader
- ‚úÖ Datas√§kerhet - allt k√∂rs lokalt
- ‚úÖ Snabbare svar - ingen n√§tverksf√∂rdr√∂jning
- ‚úÖ Alltid tillg√§nglig

**Modeller:**
- **Sentence Transformer**: Snabb, effektiv f√∂r svenska text
- **Swedish BERT**: H√∂gsta precision f√∂r svenska
- **Multilingual BERT**: St√∂der m√•nga spr√•k

### Machine Learning

- **TF-IDF Vectorizer**: Extraherar viktiga termer fr√•n texten
- **Random Forest Classifier**: Klassificerar verksamhet med h√∂g precision
- **Automatisk tr√§ning**: Modellen tr√§nas automatiskt vid f√∂rsta k√∂rningen
- **Fallback-system**: Anv√§nder AI om ML misslyckas

### Tr√§na ML-modellen

**Via webbgr√§nssnittet:**
1. Ladda upp remisser som hamnat i "osakert"
2. Klicka p√• "Omdirigera" f√∂r varje remiss
3. V√§lj r√§tt verksamhet
4. Klicka p√• "Tr√§na ML med omf√∂rdelningsdata"

**Manuellt:**
```bash
python ml_verksamhetsidentifierare.py
```

## üîÑ Omdirigering av os√§kra remisser

### Ny funktionalitet

Programmet st√∂der nu manuell omf√∂rdelnings av remisser som hamnat i "osakert":

1. **Lista os√§kra remisser**: Se alla remisser som beh√∂ver omf√∂rdelnings
2. **Omdirigera**: Flytta remisser till r√§tt verksamhet
3. **Tr√§na modellen**: Anv√§nd omf√∂rdelningsdata f√∂r att f√∂rb√§ttra ML-modellen
4. **Automatisk uppdatering**: .dat-filer uppdateras automatiskt

### API-endpoints

- `GET /api/osakert_remisser` - Lista alla os√§kra remisser
- `POST /api/omf√∂rdela_remiss` - Omdirigera en remiss
- `POST /api/tr√§na_ml_med_omf√∂rdelningsdata` - Tr√§na ML-modellen

## üéØ F√∂rb√§ttrad verksamhetsidentifiering

### Kontextbaserad analys

- **Mottagarfraser**: S√∂ker efter "remiss till", "mottagare:", etc.
- **Viktad po√§ngs√§ttning**: Nyckelord n√§ra mottagarfraser f√•r extra po√§ng
- **Specifika termer**: Separata nyckelord f√∂r gynekologi, kirurgi, etc.
- **Avs√§ndarfiltrering**: Undviker att identifiera avs√§ndaren ist√§llet f√∂r mottagaren

### Debug-verktyg

- **Steg-f√∂r-steg analys**: Se hur varje steg i identifieringen fungerar
- **Po√§ngs√§ttning**: Visa detaljerad po√§ngs√§ttning f√∂r varje metod
- **AI-analys**: Se AI:ns resonemang och sannolikhet

## üìä Webbgr√§nssnitt

Det nya webbgr√§nssnittet erbjuder:

- **Drag-and-drop**: Enkel filuppladdning
- **Realtidsstatus**: Se bearbetningsf√∂rloppet live med WebSocket
- **Statistik**: √ñversikt √∂ver bearbetade filer per verksamhet
- **AI-status**: Kontrollera AI-modellernas status och konfiguration
- **Lokal AI-kontroller**: Byt mellan olika lokala AI-modeller
- **Omdirigering**: Hantera os√§kra remisser direkt fr√•n gr√§nssnittet
- **Textanalys**: Testa verksamhetsidentifiering med valfri text
- **Debug-analys**: Steg-f√∂r-steg analys av identifieringsprocessen
- **ML-tr√§ning**: Tr√§na modellen direkt fr√•n gr√§nssnittet
- **Responsivt design**: Fungerar p√• alla enheter

### Starta webbgr√§nssnittet

```bash
# Anv√§nd det automatiskt skapade startskriptet
./start_web.sh

# Eller starta manuellt
source venv/bin/activate
python web_app.py
```

√ñppna sedan webbl√§saren p√•: http://localhost:5000

## üì§ Output-format

### .dat-filer

F√∂r varje bearbetad remiss skapas en .dat-fil med f√∂ljande format:

```
Verksamhet: Ortopedi
Personnummer: 19850415-1234
Remissdatum: 2024-01-15
Skapad: 2024-01-15 14:30:25
```

### Mappstruktur

```
output/
‚îú‚îÄ‚îÄ Ortopedi/
‚îÇ   ‚îú‚îÄ‚îÄ remiss1.pdf
‚îÇ   ‚îú‚îÄ‚îÄ remiss1.dat
‚îÇ   ‚îú‚îÄ‚îÄ remiss2.pdf
‚îÇ   ‚îî‚îÄ‚îÄ remiss2.dat
‚îú‚îÄ‚îÄ Kirurgi/
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ Gynekologi/
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ osakert/
    ‚îî‚îÄ‚îÄ ... (remisser med l√•g sannolikhet)
```

## üìù Loggning

Programmet skapar detaljerade loggar i `remiss_sorterare.log`:

- Bearbetningsstatus f√∂r varje PDF
- OCR-resultat och extraherad text
- AI-analysresultat och sannolikheter
- ML-modellens prestanda och tr√§ning
- Omdirigeringar och ML-tr√§ning
- Fel och varningar

## üîß Fels√∂kning

### Vanliga problem

1. **Tesseract inte hittas**:
   - Kontrollera att Tesseract √§r installerat
   - L√§gg till Tesseract i PATH-variabeln
   - **L√∂sning**: K√∂r `./install.sh` igen f√∂r att installera Tesseract

2. **OCR ger d√•liga resultat**:
   - Kontrollera bildkvalitet p√• PDF:erna
   - Justera DPI-inst√§llning i config.py
   - F√∂rb√§ttra skanning av originaldokument

3. **Fel verksamhet identifieras**:
   - Anv√§nd debug-analys f√∂r att se steg-f√∂r-steg
   - Kontrollera AI-konfigurationen
   - L√§gg till fler specifika termer i config.py
   - Justera tr√∂skelv√§rden

4. **AI-modeller laddas inte**:
   - Kontrollera internetanslutning (f√∂r f√∂rsta nedladdningen)
   - Verifiera att r√§tt AI-typ √§r vald i ai_config.py
   - Kontrollera att alla AI-bibliotek √§r installerade
   - **L√∂sning**: K√∂r `./install.sh` igen f√∂r att installera AI-bibliotek

5. **Installationsproblem**:
   - **L√∂sning**: K√∂r `./install.sh` f√∂r att installera allt automatiskt
   - Kontrollera att du har Python 3.8+ installerat
   - F√∂r Linux: Kontrollera att du har sudo-r√§ttigheter

### Debug-l√§ge

Aktivera debug-loggning i `config.py`:

```python
LOG_NIV√Ö = "DEBUG"
```

### AI-debug

Anv√§nd debug-verktygen i webbgr√§nssnittet:
1. Klicka p√• "Debug Analys" f√∂r steg-f√∂r-steg analys
2. Kontrollera AI-status f√∂r att se modellernas tillst√•nd
3. Testa AI med valfri text

## ‚ö° Prestanda

- **Bearbetningstid**: ~30-60 sekunder per PDF (beroende p√• sidantal och bildkvalitet)
- **Minnesanv√§ndning**: ~100-200 MB per PDF
- **AI-modeller**: 
  - Sentence Transformer: ~117MB
  - Swedish BERT: ~438MB
  - Multilingual BERT: ~1.1GB
  - Ollama-modeller: 1.7GB - 39GB (beroende p√• modell)
- **Lagringsutrymme**: ~2-5x originalfilens storlek (tempor√§ra bilder)
- **Minneskrav f√∂r Ollama**: 4GB - 32GB RAM (beroende p√• modell)

## üîí S√§kerhet

- Programmet l√§ser endast PDF-filer
- **Lokala AI-modeller**: Inga data skickas externt
- **OpenAI**: Data skickas till OpenAI (se deras sekretesspolicy)
- Loggar inneh√•ller inte k√§nslig patientinformation
- Rekommendation: K√∂r i isolerad milj√∂ f√∂r produktion

## üÜò Support

### Fels√∂kning

1. **Kontrollera loggfilen** f√∂r felmeddelanden
2. **Verifiera AI-konfiguration** i ai_config.py
3. **Testa med en enkel PDF** f√∂rst
4. **Anv√§nd debug-verktygen** i webbgr√§nssnittet
5. **K√∂r installationsskriptet igen** om du har problem: `./install.sh`

### Vanliga fr√•gor

**Q: Varf√∂r fungerar inte AI-identifiering?**
A: Kontrollera att r√§tt AI_TYPE √§r vald i ai_config.py och att alla beroenden √§r installerade.

**Q: Hur byter jag mellan olika AI-modeller?**
A: Anv√§nd "Lokal AI-kontroller" i webbgr√§nssnittet eller √§ndra LOKAL_AI_MODEL i ai_config.py.

**Q: Hur installerar jag Ollama-modeller?**
A: Anv√§nd `python ollama_manager.py install <modellnamn>` eller webbgr√§nssnittet p√• `/ollama`.

**Q: Vilken Ollama-modell ska jag v√§lja?**
A: B√∂rja med `mistral:7b-instruct` f√∂r b√§sta balans mellan kvalitet och hastighet.

**Q: Ollama startar inte - vad g√∂r jag?**
A: K√∂r `ollama serve` i en terminal och h√•ll den ig√•ng, eller starta som tj√§nst.

**Q: Kan jag anv√§nda programmet utan internet?**
A: Ja, med lokala AI-modeller fungerar allt offline efter f√∂rsta nedladdningen.

**Q: Hur installerar jag allt enkelt?**
A: K√∂r bara `./install.sh` - det installerar allt automatiskt inklusive AI-st√∂d.

**Q: Vad g√∂r installationsskriptet?**
A: Det installerar Python 3.12, Tesseract OCR, alla Python-beroenden, AI-bibliotek, skapar mappstruktur och konfigurerar allt automatiskt.

## üìÑ Licens

Detta program √§r utvecklat f√∂r intern anv√§ndning. Se till att f√∂lja relevanta riktlinjer f√∂r hantering av patientdata.

## üîÑ Uppdateringar

### Senaste versionen inneh√•ller:

- ‚úÖ AI-driven verksamhetsidentifiering
- ‚úÖ St√∂d f√∂r lokala AI-modeller
- ‚úÖ **Ollama-integration** med st√∂d f√∂r 8+ modeller
- ‚úÖ **Ollama-modellhantering** via webbgr√§nssnitt och kommandoradsverktyg
- ‚úÖ **Automatisk modellvalidering** och fallback
- ‚úÖ **F√∂rb√§ttrad PDF-konvertering** med Poppler-st√∂d
- ‚úÖ **Virtuell milj√∂kontroll** f√∂r s√§ker k√∂rning
- ‚úÖ Omdirigering av os√§kra remisser
- ‚úÖ F√∂rb√§ttrad kontextbaserad analys
- ‚úÖ Debug-verktyg f√∂r fels√∂kning
- ‚úÖ Webbgr√§nssnitt med realtidsstatus
- ‚úÖ ML-tr√§ning med omf√∂rdelningsdata
- ‚úÖ St√∂d f√∂r fler verksamheter (Gynekologi, etc.)
- ‚úÖ Komplett installationsskript med AI-st√∂d
- ‚úÖ Automatisk AI-konfiguration
- ‚úÖ Webbstartskript f√∂r enklare anv√§ndning
